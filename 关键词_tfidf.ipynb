{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba.analyse\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 原来的有点Bug，修改了\n",
    "stop = open('hit_stopwords.txt', 'r+', encoding='utf-8')\n",
    "stop_words = stop.read().split(\"\\n\") + [' ']\n",
    "stop.close()\n",
    "def skip_stop_words(text):\n",
    "    res =[]\n",
    "    for i in text:\n",
    "        for word in i:\n",
    "            if word not in stop_words:\n",
    "                res.append(word)\n",
    "            \n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample1.txt', header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = 'customer_segment_org', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_list'] = df['text_list'].map(lambda x:json.loads(x))\n",
    "df['text_list'] = df['text_list'].map(lambda x:skip_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_segment_org</th>\n",
       "      <th>text_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A-富裕</td>\n",
       "      <td>已经 申请 延期 申请 延期 申请 延期 多谢 转 人工 你好 好 不用 没有 理财 全部 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1-优质中产</td>\n",
       "      <td>逾期 几天 知道 之前 处 处理 一笔 上上个月 一期 应该 几天 搞进去 好 好 现在 现...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B2-成长中产</td>\n",
       "      <td>还 没 借到 钱 现在 应该 一千块 先 还 掉 再 看 一下 不 知道 不能 理解 差 将...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B3-成长中产</td>\n",
       "      <td>你好 说话 京东 都 给我发 短信 说 已经 说 一下 已经 给我发 短信 不让 说 说 说...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C1-优质白领</td>\n",
       "      <td>听 得到 现在 没 出去 没有 钱 付款 三月份 现在 做点 生意 之前 亏了 鞋子 应该 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C2-成长白领</td>\n",
       "      <td>号码 没有 收到 验证码 登 一下 六五 二 一八九 号码 我用 号码 登登 不 上去 九五...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C3-成长白领</td>\n",
       "      <td>不是 不是 那天 说 不是 上个月 我用 身份证 办 上个月 三十 号 刚刚 办 还 办理 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D1-优质蓝领</td>\n",
       "      <td>你好 说 好 上次 不是 协商 到时候 说 没 说 不是 现在 不是 说 暂时 处理 不了 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2-成长蓝领</td>\n",
       "      <td>说 知道 找 没有 上班 好 工作 现在 工作 不是 年底 发 工作 上 好 再见 想想 办...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D3-成长蓝领</td>\n",
       "      <td>好 你好 你好 事 不 不是 意思 账户 京东 金条 意思 这是 意思 不 知道 意思 说 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E-信息下沉</td>\n",
       "      <td>不是 好像 公司 现在 工作 没 现在 不是 现在 在家 不 知道 现在 不 知道 公司 没...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_segment_org                                          text_list\n",
       "5                  A-富裕  已经 申请 延期 申请 延期 申请 延期 多谢 转 人工 你好 好 不用 没有 理财 全部 ...\n",
       "4               B1-优质中产  逾期 几天 知道 之前 处 处理 一笔 上上个月 一期 应该 几天 搞进去 好 好 现在 现...\n",
       "10              B2-成长中产  还 没 借到 钱 现在 应该 一千块 先 还 掉 再 看 一下 不 知道 不能 理解 差 将...\n",
       "0               B3-成长中产  你好 说话 京东 都 给我发 短信 说 已经 说 一下 已经 给我发 短信 不让 说 说 说...\n",
       "6               C1-优质白领  听 得到 现在 没 出去 没有 钱 付款 三月份 现在 做点 生意 之前 亏了 鞋子 应该 ...\n",
       "8               C2-成长白领  号码 没有 收到 验证码 登 一下 六五 二 一八九 号码 我用 号码 登登 不 上去 九五...\n",
       "2               C3-成长白领  不是 不是 那天 说 不是 上个月 我用 身份证 办 上个月 三十 号 刚刚 办 还 办理 ...\n",
       "9               D1-优质蓝领  你好 说 好 上次 不是 协商 到时候 说 没 说 不是 现在 不是 说 暂时 处理 不了 ...\n",
       "1               D2-成长蓝领  说 知道 找 没有 上班 好 工作 现在 工作 不是 年底 发 工作 上 好 再见 想想 办...\n",
       "7               D3-成长蓝领  好 你好 你好 事 不 不是 意思 账户 京东 金条 意思 这是 意思 不 知道 意思 说 ...\n",
       "3                E-信息下沉  不是 好像 公司 现在 工作 没 现在 不是 现在 在家 不 知道 现在 不 知道 公司 没..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "corpus = list(df['text_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- 自定义IDF词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "idf_dic = {}\n",
    "#data_content是带分析文本，一个demo：如下图\n",
    "doc_count = len(corpus) # 总共有多少篇文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    new_content = corpus[i].split(' ')\n",
    "    for word in set(new_content):\n",
    "        idf_dic[word] = idf_dic.get(word, 0.0) + 1.0\n",
    "        # 此时idf_dic的v值：有多少篇文档有这个词，就是多少\n",
    "for k,v in idf_dic.items():\n",
    "    w = k\n",
    "    p = '%.10f' % (math.log(doc_count / (1.0 + v))) # 结合上面的tf-idf算法公式\n",
    "    if w > u'\\u4e00' and w <= u'\\u9fa5': # 判断key值全是中文\n",
    "        idf_dic[w] = p\n",
    "        \n",
    "with open('tfidf_dict.txt','w',encoding='utf-8') as f:\n",
    "    for k in idf_dic:\n",
    "        if k != '\\n':\n",
    "            f.write(k + ' ' + idf_dic[k] + '\\n') #写入txt文件，注意utf-8，否则jieba不认"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.analyse.set_idf_path('tfidf_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.967 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "tfidf = {}\n",
    "count = []\n",
    "for i in range(len(df)):\n",
    "    words = list(jieba.analyse.extract_tags(df.iloc[i, 1], topK = 500, withWeight = False))\n",
    "    tfidf[df.iloc[i, 0]] = words\n",
    "    for word in words:\n",
    "        count.append({'seg':df.iloc[i, 0], 'word':word, 'count':df.iloc[i, 1].count(word)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(tfidf)\n",
    "df_count = pd.DataFrame(count)\n",
    "df_count = df_count.groupby(['seg', 'word']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.to_csv('custgroup_keyword_Top200_tfidf.txt', sep = '\\t')\n",
    "df_count.to_csv('custgroup_keyword_Top200_count.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[9, 1].count('投资')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = []\n",
    "for index, row in df.iterrows():\n",
    "    content = row[1]\n",
    "    #TextRank 关键词抽取，只获取固定词性\n",
    "    words = jieba.analyse.extract_tags(content, topK=50,withWeight=False)\n",
    "    splitedStr = ''\n",
    "    for word in words:\n",
    "        # 记录全局分词\n",
    "        segments.append({'word':word, 'count':1})\n",
    "        splitedStr += word + ' '\n",
    "dfSg = pd.DataFrame(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "response = tfidf.fit_transform(corpus)\n",
    "feature_names = tfidf.get_feature_names()\n",
    "response_matrix = response.toarray()\n",
    "tfidf_k = np.argpartition(response_matrix, np.argmin(response_matrix, axis=0))[:, -1000:] ## 每个文档前1000关键词的index\n",
    "\n",
    "ans = []\n",
    "for i in range(len(df)):\n",
    "    res = []\n",
    "    for index in list(tfidf_k[i]):\n",
    "        if feature_names[index] in corpus[i].split(' '):\n",
    "            res.append(feature_names[index])\n",
    "    ans.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "k = 3\n",
    "model = KMeans(n_clusters=k)\n",
    "\n",
    "model.fit(response_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "tsne.fit_transform(response_matrix) #进行数据降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = pd.DataFrame(tsne.embedding_) #转换数据格式\n",
    "tsne['label'] = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tsne' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2823049d6063>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'axes.unicode_minus'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;31m#用来正常显示负号\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#不同类别用不同颜色和样式绘图\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtsne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtsne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tsne' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False #用来正常显示负号\n",
    "#不同类别用不同颜色和样式绘图\n",
    "d = tsne[tsne['label'] == 0]\n",
    "plt.plot(d[0], d[1], 'r.')\n",
    "d = tsne[tsne['label'] == 1]\n",
    "plt.plot(d[0], d[1], 'go')\n",
    "d = tsne[tsne['label'] == 2]\n",
    "plt.plot(d[0], d[1], 'b*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}